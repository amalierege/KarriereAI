{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KarriereAI\n",
    "#### A deep learning model used to predict viable career paths to a user based on their skills and interests.\n",
    "\n",
    "#### Purpose\n",
    "KarriereAI will classify the appropriate career within technology for a user from an interactive quizlet input. The quizlet is used to determine the user's skills and interests, before the model will predict a fitting career based on the input data.\n",
    "\n",
    "#### Dataset\n",
    "The dataset to be used is from the paper Skill2vec: A Machine Learning Approach for Determining the Relevant Skills from Job Description, by Van-Duyet Le et al. <a href=\"https://arxiv.org/pdf/1707.09751\">here</a>. Containing relevant columns of job titles related to a free-text field of job descriptions describing relevant skills. \n",
    "\n",
    "#### Model Architecture\n",
    "The main model is a feed-forward neural network (FNN) for classification, using a multi-layer-perceptron (MLP) architecture suitable for structured data classification. \n",
    "\n",
    "Part of engineering the main model requires preprocessing of the dataset in a natural language processing (NLP) set-up, preparing it to run through a sub-model with an encoded transformer architecture.\n",
    "\n",
    "The main model also requires figuring out basic vs. deep MLP architecures. Additionally, figuring out whether the model should contain batch normalization, regularization and/or dropout. Lastly, experimenting with different activation functions.\n",
    "\n",
    "Through using the NLP sub-model, the data will be vectorized to work with the MLP classifier rather than the language model.\n",
    "\n",
    "#### Evaluation\n",
    "As far as evaluation goes, a confusion matrix and an F1 score will be computed along with standard evaluation metrics like accuracy, recall and precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Importing Libraries and Loading the Data \n",
    "We will be needing different libraries from <a href=\"https://keras.io/api/\">Keras</a> and <a href=\"https://www.tensorflow.org/api_docs/python/tf\">TensorFlow</a> among others to make computations on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Model processing\n",
    "import sklearn\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import layers, Sequential\n",
    "from scipy import sparse\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Other\n",
    "import datetime\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "import matplotlib as plot\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "from pathlib import Path\n",
    "import seaborn\n",
    "seaborn.set_theme (style = \"whitegrid\")\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing relevant libraries, we load the dataset we wish to train the model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pandas.read_csv (\"data/mustHaveSkills.csv\", header = 0, encoding ='ISO-8859-1')\n",
    "del data ['job_brief_id']\n",
    "\n",
    "# REF: Van-Duyet Le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Taking a Look at the Data\n",
    "\n",
    "To create optimal and smooth-running Python for the model we want to  study the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (261724, 2) \n",
      "\n",
      "Information about dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261724 entries, 0 to 261723\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   keyword_name  261717 non-null  object\n",
      " 1   job_title     261724 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ MB\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Basic information about dataset\n",
    "print (\"Shape of dataset:\", data.shape, \"\\n\")\n",
    "print (\"Information about dataset:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Exploratory Data Analysis (EDA)\n",
    "\n",
    "To know what data the model will injest, taking a closer look by constructing plots and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Plotting Jobs and Skills\n",
    "##### 3.1.1 Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Function to count number of occurrences \n",
    "def count_items(series):\n",
    "    items = series.dropna().apply(lambda x: x.split(\";\"))\n",
    "    flat_list = [item.strip() for sublist in items for item in sublist]\n",
    "    return pandas.Series(flat_list).value_counts()\n",
    "\n",
    "# REF: Adil Shamim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Jobs:\n",
      " Software Engineer                       4140\n",
      "software engineer                       3954\n",
      "software developer                      2612\n",
      "engineer                                2190\n",
      "consultant                              1826\n",
      "                                        ... \n",
      "css programmer                             1\n",
      "css developer                              1\n",
      "Clinical Research Asscociate               1\n",
      "Business Solution Security Architect       1\n",
      "Acccount                                   1\n",
      "Name: count, Length: 5650, dtype: int64\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Count Jobs\n",
    "job_count = count_items(data[\"job_title\"])\n",
    "print(\"Most Common Jobs:\\n\", job_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2 Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Skills:\n",
      " C++                                               3024\n",
      "Java                                              2928\n",
      "Python                                            1606\n",
      "J2EE                                              1518\n",
      "C#                                                1362\n",
      "                                                  ... \n",
      "Shaders                                              1\n",
      "Mel                                                  1\n",
      "Accessible Rich Internet Applications WAI-ARIA       1\n",
      "LTL                                                  1\n",
      "RTL page designs                                     1\n",
      "Name: count, Length: 8586, dtype: int64\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Count Skills\n",
    "skills_count = count_items(data[\"keyword_name\"])\n",
    "print(\"Most Common Skills:\\n\", skills_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Preprocessing of Data\n",
    "\n",
    "For the purpose of cleaning the dataset to make sure the model doesn't learn errors making predictions skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 String Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 80810 entries, 0 to 261723\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   keyword_name  80803 non-null  object\n",
      " 1   job_title     80810 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.8+ MB\n",
      "None\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "data = data.drop_duplicates (subset = ['keyword_name', 'job_title'], keep = 'last')\n",
    "data = data [data [\"job_title\"] != 0]\n",
    "print (data.info())\n",
    "\n",
    "# String magic\n",
    "data ['Count'] = data.groupby ('job_title')['keyword_name'].transform (pandas.Series.value_counts)\n",
    "data.drop_duplicates (inplace = True)\n",
    "# data ['keyword_name'] = data ['keyword_name'].str.lower()\n",
    "# data ['keyword_name'] = data ['keyword_name'].str.replace(' ', '_')\n",
    "# data ['job_title'] = data ['job_title'].str.lower()\n",
    "\n",
    "# Clean data\n",
    "data_jobtitle = data.groupby ('job_title')['keyword_name'].apply(list)\n",
    "\n",
    "# REF: Van-Duyet Le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Vectorization\n",
    "Turning skills and interests into vectorized numerical features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define features to be used\n",
    "features = data [['job_title', 'keyword_name']]\n",
    "skills = data ['keyword_name']\n",
    "target = data ['job_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title\n",
       ".NET                               [Microsoft Office SharePoint Server]\n",
       ".NET Developer        [sharepoint, MOSS, ASP.Net, HTML/HTML5, CSS/CS...\n",
       ".NET developer        [SQL, Finance, Bank, banking, FSI, FI, FS, Fin...\n",
       ".Net Application                         [architect, .net, asp.net, C#]\n",
       ".Net Developer                               [Microsoft .NET, .Net, C#]\n",
       "                                            ...                        \n",
       "workday consultant    [workday, workday HCM, Mandarin, Cantonese, Ch...\n",
       "world design          [Level, Levels, world, worlds, design, Multipl...\n",
       "world designer        [Level, Levels, world, worlds, design, Multipl...\n",
       "writer                [agency, copywriting, copywriter, writer, writ...\n",
       "writing               [agency, copywriting, copywriter, writer, writ...\n",
       "Name: keyword_name, Length: 5649, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Look at contents of dataset\n",
    "data_jobtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 15:34:50.892195: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      3\u001b[39m vectorizer = keras.layers.TextVectorization (\n\u001b[32m      4\u001b[39m     max_tokens = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m      5\u001b[39m     standardize = \u001b[33m\"\u001b[39m\u001b[33mlower_and_strip_punctuation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     name = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m vectorizer.adapt (target)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43madapt\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mskills\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/nonsense/Amalie/karriere_ai/venv/lib64/python3.12/site-packages/keras/src/layers/preprocessing/text_vectorization.py:423\u001b[39m, in \u001b[36mTextVectorization.adapt\u001b[39m\u001b[34m(self, data, batch_size, steps)\u001b[39m\n\u001b[32m    421\u001b[39m         \u001b[38;5;28mself\u001b[39m.update_state(batch)\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     data = \u001b[43mtf_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mensure_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstring\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data.shape.rank == \u001b[32m1\u001b[39m:\n\u001b[32m    425\u001b[39m         \u001b[38;5;66;03m# A plain list of strings\u001b[39;00m\n\u001b[32m    426\u001b[39m         \u001b[38;5;66;03m# is treated as as many documents\u001b[39;00m\n\u001b[32m    427\u001b[39m         data = tf.expand_dims(data, -\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/nonsense/Amalie/karriere_ai/venv/lib64/python3.12/site-packages/keras/src/utils/tf_utils.py:37\u001b[39m, in \u001b[36mensure_tensor\u001b[39m\u001b[34m(inputs, dtype)\u001b[39m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m backend.backend() == \u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m backend.is_tensor(inputs):\n\u001b[32m     35\u001b[39m         \u001b[38;5;66;03m# Plain `np.asarray()` conversion fails with PyTorch.\u001b[39;00m\n\u001b[32m     36\u001b[39m         inputs = backend.convert_to_numpy(inputs)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     inputs = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs.dtype != dtype:\n\u001b[32m     39\u001b[39m     inputs = tf.cast(inputs, dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/nonsense/Amalie/karriere_ai/venv/lib64/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/nonsense/Amalie/karriere_ai/venv/lib64/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[39m, in \u001b[36mconvert_to_eager_tensor\u001b[39m\u001b[34m(value, ctx, dtype)\u001b[39m\n\u001b[32m    106\u001b[39m     dtype = dtypes.as_dtype(dtype).as_datatype_enum\n\u001b[32m    107\u001b[39m ctx.ensure_initialized()\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vectorizer = keras.layers.TextVectorization (\n",
    "    max_tokens = None,\n",
    "    standardize = \"lower_and_strip_punctuation\",\n",
    "    split = \"character\",\n",
    "    ngrams = None, # we can insert a bigram (N-gram of 2)\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = None,\n",
    "    pad_to_max_tokens = False,\n",
    "    vocabulary = None,\n",
    "    idf_weights = None,\n",
    "    sparse = False,\n",
    "    ragged = False,\n",
    "    encoding = \"utf-8\",\n",
    "    name = None\n",
    ")\n",
    "\n",
    "vectorizer.adapt (target)\n",
    "vectorizer.adapt (skills)\n",
    "\n",
    "# REF: Keras Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Embedding the Data\n",
    "To be able to run the data through a transformer, it needs to be embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 The Transformer Model\n",
    "Utilize the tokenized version of the data, to produce an output suitable for the MLP classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Building the MLP Model\n",
    "\n",
    "Building the FFN model, and training it on training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Constructing the Feature Matrix\n",
    "\n",
    "Combining the numerical value of Age with the vectorized Skills and Interest features into a sparse matrix concatenation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Training, Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print (type(feature_matrix), type(encoded_target))\n",
    "\n",
    "X_train = feature_matrix \n",
    "y_train = encoded_target \n",
    "\n",
    "X_train = tensorflow.sparse.reorder(X_train)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split (feature_matrix, encoded_target, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# tensorflow.sparse.reorder(X_train)\n",
    "\n",
    "# this is trash:\n",
    "# training_set, validation_set, test_set = train_val_test_split (age_matrix, feature_matrix, )\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Training the MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Remove previous logs\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.0437 - loss: 0.5685 - val_accuracy: 0.0250 - val_loss: 0.0411\n",
      "Epoch 2/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0378 - loss: 0.0684 - val_accuracy: 0.0250 - val_loss: 0.0181\n",
      "Epoch 3/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0841 - loss: 0.0267 - val_accuracy: 0.0250 - val_loss: 0.0108\n",
      "Epoch 4/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0272 - loss: 0.0433 - val_accuracy: 0.0000e+00 - val_loss: 0.0097\n",
      "Epoch 5/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0524 - loss: 0.0202 - val_accuracy: 0.0250 - val_loss: 0.0147\n",
      "Epoch 6/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0425 - loss: 0.0249 - val_accuracy: 0.0000e+00 - val_loss: 0.0098\n",
      "Epoch 7/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0897 - loss: 0.0266 - val_accuracy: 0.0000e+00 - val_loss: 0.0153\n",
      "Epoch 8/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0141 - loss: 0.0606 - val_accuracy: 0.0250 - val_loss: 0.0060\n",
      "Epoch 9/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0368 - loss: 0.0936 - val_accuracy: 0.0250 - val_loss: 0.0106\n",
      "Epoch 10/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0261 - loss: 0.0334 - val_accuracy: 0.0250 - val_loss: 0.0096\n",
      "Epoch 11/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0102 - loss: 0.0270 - val_accuracy: 0.0250 - val_loss: 0.0159\n",
      "Epoch 12/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0233 - loss: 0.0192 - val_accuracy: 0.0250 - val_loss: 0.0166\n",
      "Epoch 13/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0212 - loss: 0.0291 - val_accuracy: 0.0250 - val_loss: 0.0086\n",
      "Epoch 14/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0399 - loss: 0.0262 - val_accuracy: 0.0250 - val_loss: 0.0156\n",
      "Epoch 15/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0063 - loss: 0.0136 - val_accuracy: 0.0500 - val_loss: 0.0206\n",
      "Epoch 16/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0218 - loss: 0.0403 - val_accuracy: 0.0250 - val_loss: 0.0048\n",
      "Epoch 17/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0079 - loss: 0.0470 - val_accuracy: 0.0250 - val_loss: 0.0205\n",
      "Epoch 18/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0192 - loss: 0.0816 - val_accuracy: 0.0250 - val_loss: 0.0128\n",
      "Epoch 19/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0127 - loss: 0.0425 - val_accuracy: 0.0250 - val_loss: 0.0073\n",
      "Epoch 20/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0412 - loss: 0.0132 - val_accuracy: 0.0750 - val_loss: 0.0204\n",
      "Epoch 21/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0123 - loss: 0.0490 - val_accuracy: 0.0750 - val_loss: 0.0214\n",
      "Epoch 22/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0376 - loss: 0.0322 - val_accuracy: 0.0250 - val_loss: 0.0242\n",
      "Epoch 23/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0388 - loss: 0.0261 - val_accuracy: 0.0250 - val_loss: 0.0244\n",
      "Epoch 24/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0070 - loss: 0.0333 - val_accuracy: 0.0000e+00 - val_loss: 0.0321\n",
      "Epoch 25/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0380 - loss: 0.0643 - val_accuracy: 0.0250 - val_loss: 0.0074\n",
      "Epoch 26/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0169 - loss: 0.0530 - val_accuracy: 0.0250 - val_loss: 0.0175\n",
      "Epoch 27/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0299 - loss: 0.0084 - val_accuracy: 0.0000e+00 - val_loss: 0.0328\n",
      "Epoch 28/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0155 - loss: 0.0326 - val_accuracy: 0.0500 - val_loss: 0.0150\n",
      "Epoch 29/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0068 - loss: 0.0275 - val_accuracy: 0.0250 - val_loss: 0.0177\n",
      "Epoch 30/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0380 - loss: 0.0152 - val_accuracy: 0.0500 - val_loss: 0.0156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27e43a62c50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    keras.Input (shape = (feature_matrix.shape[1], )),\n",
    "    # to complete the embedding, a one-hot layer:layers.StringLookup (output_mode = \"one-hot\")\n",
    "    layers.Dropout (0.1),\n",
    "    layers.Dense (16, activation = 'relu'),\n",
    "    layers.Dense (16, activation = 'relu'),\n",
    "    # followed by a Dense layer: layers.Dense (units = embedding_dim, use_bias = False, activation = None)\n",
    "    layers.Dense (target.unique().size)\n",
    "])\n",
    "\n",
    "# model.compile(loss = 'SparseCategoricalCrossentropy', optimizer = 'adam')\n",
    "model.compile (loss = 'hinge', \n",
    "              optimizer = 'adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tensorflow.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)\n",
    "\n",
    "model.fit (X_train, y_train, \n",
    "          epochs = 30, \n",
    "          batch_size = 1, \n",
    "          validation_split = 0.2,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">151</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m151\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m2,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,378</span> (44.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,378\u001b[0m (44.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,792</span> (14.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,792\u001b[0m (14.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,586</span> (29.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m7,586\u001b[0m (29.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20476), started 1 day, 13:53:40 ago. (Use '!kill 20476' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-42f90d4aacb34269\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-42f90d4aacb34269\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "# y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Confusion matrix\n",
    "# cm = confusion_matrix(y_train, y_pred)\n",
    "# plot.figure(figsize = (10, 8))\n",
    "# seaborn.heatmap(cm, annot = True, fmt = \"d\", cmap = \"Blues\",\n",
    "#             xticklabels = target_encoder.classes_,\n",
    "#             yticklabels = target_encoder.classes_)\n",
    "# plot.xlabel(\"Predicted\")\n",
    "# plot.ylabel(\"Actual\")\n",
    "# plot.title(\"Confusion Matrix\")\n",
    "# plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Precision, Accuracy, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
